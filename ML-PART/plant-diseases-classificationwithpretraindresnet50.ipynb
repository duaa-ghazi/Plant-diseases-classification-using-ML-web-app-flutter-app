{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"####Import Library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, \nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom keras.layers import ZeroPadding2D, Activation, BatchNormalization,GlobalAveragePooling2D\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau, EarlyStopping\nimport glob\nimport cv2\nimport tensorflow as tf\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\nimport splitfolders\nfrom keras.models import Model\nfrom keras.optimizers import SGD , Adam\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing import image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(glob.glob(\"../input/plantvillage-dataset/color/Tomato___healthy\"+\"/*\")))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"###Define Constants\nFAST_RUN = False\nIMAGE_WIDTH=224\nIMAGE_HEIGHT=224\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nbatch_size = 128\nepochs = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install split-folders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install split-folders tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import splitfolders\nsplitfolders.ratio('../input/plantvillage-dataset/color', output=\"output\", seed=1337, ratio=(.7, .15,.15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_directory  = \"./output/train\"\nvalidation_data_directory  = \"./output/val\"\ntest_data_directory=\"./output/test\"\nnum_of_classes_on_trainDataset=print(len(glob.glob(train_data_directory +\"/*\")))\nnum_of_classes_on_valDataset=print(len(glob.glob(validation_data_directory+\"/*\")))\nnum_of_classes_on_testDataset=print(len(glob.glob(test_data_directory+\"/*\")))\n\n\n##Image Preprocessing\ntrain_datagenerator = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   rotation_range=40,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\nvalid_datagenerator = ImageDataGenerator(rescale=1./255)\n\ntraining_set = train_datagenerator.flow_from_directory(train_data_directory ,\n                                                 target_size=IMAGE_SIZE,\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagenerator.flow_from_directory(validation_data_directory,\n                                            target_size=IMAGE_SIZE,\n                                            batch_size=batch_size,\n                                            class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagenerator = ImageDataGenerator(rescale=1./255)\ntest_set = test_datagenerator.flow_from_directory(\n    test_data_directory, \n    class_mode='categorical',\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)\n\n\nnumber_of_classes= print(len(glob.glob(train_data_directory +\"/*\")))\nnumber_of_train_images=training_set.samples\nprint(number_of_train_images)\nnumber_of_val_images=valid_set.samples\nprint(number_of_val_images)\nnumber_of_test_images=test_set.samples\nprint(number_of_test_images)\n\n\n\nprint(training_set.class_indices)\n\n\nlist_of_classes = list(training_set.class_indices.keys())\nprint(list_of_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##See Random sample image\nsample_type= random.choice(list_of_classes)\nprint(sample_type)\n\nsample_random_img= random.choice(os.listdir(train_data_directory+\"/\"+sample_type))\nprint(sample_random_img)\n\nimage=load_img(train_data_directory+\"/\"+sample_type+\"/\"+sample_random_img)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getSamplesFromDataGen(resultData):\n    x = resultData.next() #fetch the first batch\n    a = x[0] # train data\n    for i in range(0,5):\n        plt.imshow(a[i])\n        \n        plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"getSamplesFromDataGen(training_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\nbase_model = tf.keras.applications.ResNet50(include_top=False,\n                   weights=\"imagenet\" ,\n                   input_shape=(224, 224, 3))\n    \n    \nprint(base_model.summary())    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (len(base_model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\nfrom keras.optimizers import SGD , Adam\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.5)(x)\nx = Dense(1024, activation='relu')(x)\nx = Dropout(0.5)(x)\npredictions = Dense(38, activation='softmax')(x)\n\nNewModel = Model(base_model.input ,  predictions)\n\n\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nNewModel.compile(loss='categorical_crossentropy',\n     metrics=['accuracy'],\n    optimizer=Adam(1e-3))\n\nNewModel.fit_generator( training_set,  steps_per_epoch=number_of_train_images//batch_size,\n                         validation_data=valid_set,\n                         epochs=3,\n                         validation_steps=number_of_val_images//batch_size,\n                         #callbacks=[checkpoint],\n                          verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in NewModel.layers:\n    layer.trainable = True\n    \nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=9)  \nreduceLROnPlat= ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, \n                                   verbose=1, mode='min', epsilon=0.0001)  \ncheckpoint= ModelCheckpoint('Pre_Resnet50.hdf5',   monitor = 'accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\ncallbacks_list = [checkpoint,  reduceLROnPlat, early ]    \n    \nNewModel.compile(loss='categorical_crossentropy',\n            optimizer=Adam(lr=1e-4),\n            metrics=['accuracy'])\n\nhistory_train=NewModel.fit_generator(    training_set, \n                       steps_per_epoch=number_of_train_images//batch_size,\n                         validation_data=valid_set,\n                         epochs=epochs,\n                         validation_steps=number_of_val_images//batch_size,\n                         callbacks=callbacks_list,\n                          verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = NewModel.evaluate_generator(test_set, steps=number_of_test_images, verbose=1,workers=3)\nprint('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\nacc = history_train.history['accuracy']\nval_acc = history_train.history['val_accuracy']\nloss = history_train.history['loss']\nval_loss = history_train.history['val_loss']\n\nepochs = range(len(acc))\n#Accuracy\nxmin = 0.0\nxmax = 8.0\nymin =0\nymax = 1.0\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n#Loss\nxmin = 0.0\nxmax = 8.0\nymin = 0.0\nymax = 1\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nsample_type= random.choice(list_of_classes)\nprint(\" original filename \" + sample_type)\n\nsample_random_img= random.choice(os.listdir(test_data_directory+\"/\"+sample_type))\n\n\nnew_image=load_img(test_data_directory+\"/\"+sample_type+\"/\"+sample_random_img ,target_size=(227, 227))\n\n\nimg = image.img_to_array(new_image)\nimg = np.expand_dims(img, axis=0)\nimg = img/255\n\nprint(\"Following is our prediction:\")\nprediction = NewModel.predict(img)\n\n\nd = prediction.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = list_of_classes[index]\n    \n\nimg_prob = j\nprint(img_prob )\n\nplt.figure(figsize = (4,4))\nplt.imshow(new_image)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}