{"cells":[{"cell_type":"code","source":"# %% [code]\n####Import Library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense,ZeroPadding2D, Activation, BatchNormalization\n\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau, EarlyStopping\n\nimport glob\nimport cv2\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\n\n\n\n# %% [code]\n\n###Define Constants\nFAST_RUN = False\nIMAGE_WIDTH=227\nIMAGE_HEIGHT=227\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nbatch_size = 32\nepochs = 15\n\n# %% [code]\npip install split-folders\n\n# %% [code]\npip install split-folders tqdm\n\n# %% [code]\nimport split_folders\n\nsplit_folders.ratio('../input/plantvillage-dataset/color', output=\"output\", seed=1337, ratio=(.7, .15,.15))\n\n\n\n# %% [code]\n\ntrain_data_directory  = \"./output/train\"\nvalidation_data_directory  = \"./output/val\"\ntest_data_directory=\"./output/test\"\nnum_of_classes_on_trainDataset=print(len(glob.glob(train_data_directory +\"/*\")))\nnum_of_classes_on_valDataset=print(len(glob.glob(validation_data_directory+\"/*\")))\nnum_of_classes_on_testDataset=print(len(glob.glob(test_data_directory+\"/*\")))\n\n\n\n\n# %% [code]\n##Image Preprocessing\n\ntrain_datagenerator = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   rotation_range=40,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\n\nvalid_datagenerator = ImageDataGenerator(rescale=1./255)\n\n\n\ntraining_set = train_datagenerator.flow_from_directory(train_data_directory ,\n                                                 target_size=IMAGE_SIZE,\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagenerator.flow_from_directory(validation_data_directory,\n                                            target_size=IMAGE_SIZE,\n                                            batch_size=batch_size,\n                                            class_mode='categorical')\n\ntest_datagenerator = ImageDataGenerator(rescale=1./255)\ntest_set = test_datagenerator.flow_from_directory(\n    test_data_directory, \n    class_mode=None,\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)\n\n# %% [code]\nnumber_of_classes= print(len(glob.glob(train_data_directory +\"/*\")))\nnumber_of_train_images=training_set.samples\nprint(number_of_train_images)\nnumber_of_val_images=valid_set.samples\nprint(number_of_val_images)\nnumber_of_test_images=test_set.samples\nprint(number_of_test_images)\n\n\n\n\n\n\n# %% [code]\nprint(training_set.class_indices)\n\n# %% [code]\nlist_of_classes = list(training_set.class_indices.keys())\nprint(list_of_classes)\n\n\n# %% [code]\n\n##See Random sample image\n\nsample_type= random.choice(list_of_classes)\nprint(sample_type)\n\nsample_random_img= random.choice(os.listdir(train_data_directory+\"/\"+sample_type))\nprint(sample_random_img)\n\nimage=load_img(train_data_directory+\"/\"+sample_type+\"/\"+sample_random_img)\nplt.imshow(image)\n\n\n# %% [code]\n\n##Build Model\nmodel = Sequential()\n\n# Layer 1\nmodel.add(Conv2D(96, kernel_size=(11,11), strides= 4, padding= 'valid', activation= 'relu',\n                        input_shape= (227,227,3), kernel_initializer= 'he_normal'))\nmodel.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),padding= 'valid', data_format= None))\nmodel.add(BatchNormalization())\n\n\n\n# Layer 2\nmodel.add(Conv2D(256, kernel_size=(5,5), strides= 1,  padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\nmodel.add(MaxPooling2D(pool_size=(3,3), strides= (2,2), padding= 'valid', data_format= None)) \nmodel.add(BatchNormalization())\n\n\n\n# Layer 3\n\nmodel.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\n\nmodel.add(BatchNormalization())\n# Dropout\nmodel.add(Dropout(0.5))\n\n#layer 4\n\nmodel.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n                        padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nmodel.add(BatchNormalization())\n# Dropout\nmodel.add(Dropout(0.5))\n\n# Layer 5\n\nmodel.add(Conv2D(256, kernel_size=(3,3), strides= 1,  padding= 'same', activation= 'relu',\n                        kernel_initializer= 'he_normal'))\n\nmodel.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),  padding= 'valid', data_format= None))\n\n# Dropout\nmodel.add(Dropout(0.5))\n          \n          \n# Layer 6\n\nmodel.add(Flatten())\n\nmodel.add(Dense(4096, activation= 'relu'))\nmodel.add(Dropout(0.5))\n          # Batch Normalisation\nmodel.add(BatchNormalization())\n\n# Layer 7\nmodel.add(Dense(4096, activation= 'relu'))\nmodel.add(Dropout(0.5))\n          \nmodel.add(BatchNormalization())\n\n# Layer 8\nmodel.add(Dense(1000, activation= 'relu'))\nmodel.add(Dropout(0.5))\n          \n# Batch Normalisation\nmodel.add(BatchNormalization())\n\n# final layer\nmodel.add(Dense(38, activation= 'softmax'))\n\n\nmodel.summary()\n\n\n# %% [code]\n\n#model.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n #                   loss='categorical_crossentropy',\n  #                  metrics=['accuracy'])\n#model.compile(optimizer=optimizers.SGD(lr=0.001, momentum=0.9, decay=0.005),\n \n    #loss='categorical_crossentropy',\n     #         metrics=['accuracy'])\nimport tensorflow as tf\nfrom tensorflow.python.keras.optimizers import Adam  \n    \nopt = tf.keras.optimizers.Adam(lr = 1e-4, decay = 1e-6)\nmodel.compile(loss=\"binary_crossentropy\", optimizer = opt,metrics = [\"accuracy\"])\n\n\n# %% [code]\n \n##Callbacks\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau ,ModelCheckpoint\n\n#earlystop = EarlyStopping(min_delta=0.001, patience=10)\n#learning_rate_reduction = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n\n#callbacks_list = [learning_rate_reduction,earlystop ]\n\n#lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n#early_stopper = EarlyStopping(min_delta=0.001, patience=10)\n\ncheckpoint = ModelCheckpoint(\"AlexNet.h5\", monitor = 'accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\n\nhistory_train= model.fit_generator(training_set,\n                         steps_per_epoch=number_of_train_images//batch_size,\n                         validation_data=valid_set,\n                         epochs=epochs,\n                         validation_steps=number_of_val_images//batch_size,\n                         callbacks=[checkpoint],\n                          verbose=1\n                         )\n\nfilepath=\"AlexNet_Model.hdf5\"\nmodel.save(filepath)\n\n\n# %% [code]\nimport matplotlib.pyplot as plt\nxmin = 0\nxmax = 15\nymin = 0.0\nymax = 1.0\nacc = history_train.history['accuracy']\nval_acc = history_train.history['val_accuracy']\nloss = history_train.history['loss']\nval_loss = history_train.history['val_loss']\n\nepochs = range(len(acc))\n\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\n# %% [code]\nprint(\"[INFO] Calculating model accuracy\")\nscores = model.evaluate_generator(generator=valid_set\n)\nprint(f\"Test Accuracy: {scores[1]*100}\")\n\n# %% [code]\nfrom keras.preprocessing import image\nsample_type= random.choice(list_of_classes)\nprint(sample_type)\n\nsample_random_img= random.choice(os.listdir(test_data_directory+\"/\"+sample_type))\n\n\nnew_image=load_img(test_data_directory+\"/\"+sample_type+\"/\"+sample_random_img ,target_size=(227, 227))\n\n\nimg = image.img_to_array(new_image)\nimg = np.expand_dims(img, axis=0)\nimg = img/255\n\nprint(\"Following is our prediction:\")\nprediction = model.predict(img)\nd = prediction.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = list_of_classes[index]\n    \n\nimg_prob =model.predict_proba(img)\nprint(img_prob.max() )\n\nplt.figure(figsize = (4,4))\nplt.imshow(new_image)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","metadata":{"collapsed":false,"_kg_hide-input":false},"execution_count":0,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}