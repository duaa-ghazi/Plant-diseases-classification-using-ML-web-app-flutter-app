{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"####Import Library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense,ZeroPadding2D, Activation, BatchNormalization,GlobalAveragePooling2D\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau, EarlyStopping\nimport glob\nimport cv2\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Define Constants\nFAST_RUN = False\nIMAGE_WIDTH=299\nIMAGE_HEIGHT=299\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nbatch_size = 128\nepochs = 8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install split-folders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import split_folders\nsplit_folders.ratio('../input/plantvillage-dataset/color', output=\"output\", seed=1337, ratio=(.7, .15,.15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_directory  = \"./output/train\"\nvalidation_data_directory  = \"./output/val\"\ntest_data_directory=\"./output/test\"\nnum_of_classes_on_trainDataset=print(len(glob.glob(train_data_directory +\"/*\")))\nnum_of_classes_on_valDataset=print(len(glob.glob(validation_data_directory+\"/*\")))\nnum_of_classes_on_testDataset=print(len(glob.glob(test_data_directory+\"/*\")))\n\n\n##Image Preprocessing\ntrain_datagenerator = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   rotation_range=40,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\nvalid_datagenerator = ImageDataGenerator(rescale=1./255)\ntraining_set = train_datagenerator.flow_from_directory(train_data_directory ,\n                                                 target_size=IMAGE_SIZE,\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagenerator.flow_from_directory(validation_data_directory,\n                                            target_size=IMAGE_SIZE,\n                                            batch_size=batch_size,\n                                            class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagenerator = ImageDataGenerator(rescale=1./255)\ntest_set = test_datagenerator.flow_from_directory(\n    test_data_directory, \n    class_mode='categorical',\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)\n\n\nnumber_of_classes= print(len(glob.glob(train_data_directory +\"/*\")))\nnumber_of_train_images=training_set.samples\nprint(number_of_train_images)\nnumber_of_val_images=valid_set.samples\nprint(number_of_val_images)\nnumber_of_test_images=test_set.samples\nprint(number_of_test_images)\n\n\n\nprint(training_set.class_indices)\n\n\nlist_of_classes = list(training_set.class_indices.keys())\nprint(list_of_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##See Random sample image\nsample_type= random.choice(list_of_classes)\nprint(sample_type)\n\nsample_random_img= random.choice(os.listdir(train_data_directory+\"/\"+sample_type))\nprint(sample_random_img)\n\nimage=load_img(train_data_directory+\"/\"+sample_type+\"/\"+sample_random_img)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nbase_model=tf.keras.applications.InceptionV3(\n    include_top= False ,\n    input_shape=(299, 299, 3),\n    weights=\"imagenet\" )\n\nprint(base_model.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (len(base_model.layers))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import inception_v3\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for layer in model.layers:\n #   layer.trainable = False\nfrom keras.models import Model\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n# let's add a fully-connected layer\nx = Dense(1024, activation='relu')(x)\n# and a logistic layer -- let's say we have 200 classes\npredictions = Dense(38, activation='softmax')(x)\n\n# this is the model we will train\nNewModel = Model(base_model.input ,  predictions)\n\nfor layer in base_model.layers:\n    layer.trainable = False\n    \nNewModel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n\nhistory_train_top= NewModel.fit_generator(training_set,\n                         steps_per_epoch=number_of_train_images//batch_size,\n                         validation_data=valid_set,\n                         epochs=3,\n                         validation_steps=number_of_val_images//batch_size,\n                         #callbacks=[checkpoint],\n                          verbose=1\n                         )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# at this point, the top layers are well trained and we can start fine-tuning\n# convolutional layers from inception V3. We will freeze the bottom N layers\n# and train the remaining top layers.\n\n# let's visualize layer names and layer indices to see how many layers\n# we should freeze:\nfor i, layer in enumerate(base_model.layers):\n   print(i, layer.name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 172 layers and unfreeze the rest:\nfor layer in model.layers[:172]:\n   layer.trainable = False\nfor layer in model.layers[172:]:\n   layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\n\n\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau ,ModelCheckpoint\n\nfrom keras.optimizers import SGD\n\nNewModel.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n\ncheckpoint = ModelCheckpoint(\"INC_V3_Pre.hdf5\",  monitor = 'accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\nhistory_train= NewModel.fit_generator(training_set,\n                         steps_per_epoch=number_of_train_images//batch_size,\n                         validation_data=valid_set,\n                         epochs=epochs,\n                         validation_steps=number_of_val_images//batch_size,\n                         callbacks=[checkpoint],\n                          verbose=1\n                         )\n\n\nfilepath=\"INC_V3_Pre.h5\"\nNewModel.save(filepath)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nloss, acc = NewModel.evaluate_generator(test_set, steps=number_of_test_images, verbose=1,workers=3)\nprint('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\nacc = history_train.history['accuracy']\nval_acc = history_train.history['val_accuracy']\nloss = history_train.history['loss']\nval_loss = history_train.history['val_loss']\n\nepochs = range(len(acc))\n#Accuracy\nxmin = 0.0\nxmax = 8.0\nymin =0\nymax = 1.0\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n#Loss\nxmin = 0.0\nxmax = 8.0\nymin = 0.0\nymax = 1\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nsample_type= random.choice(list_of_classes)\nprint(\" original filename \" + sample_type)\n\nsample_random_img= random.choice(os.listdir(test_data_directory+\"/\"+sample_type))\n\n\nnew_image=load_img(test_data_directory+\"/\"+sample_type+\"/\"+sample_random_img ,target_size=(227, 227))\n\n\nimg = image.img_to_array(new_image)\nimg = np.expand_dims(img, axis=0)\nimg = img/255\n\nprint(\"Following is our prediction:\")\nprediction = NewModel.predict(img)\n\n\nd = prediction.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = list_of_classes[index]\n    \n\nimg_prob = j\nprint(img_prob )\n\nplt.figure(figsize = (4,4))\nplt.imshow(new_image)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage.segmentation import mark_boundaries\nfrom lime.wrappers.scikit_image import SegmentationAlgorithm\nimport sklearn\nimport sklearn.datasets\nimport sklearn.ensemble\n\nimport lime\nimport lime.lime_tabular\nfrom lime import lime_image\n#from  __future__ import print_function\nexec('from __future__ import absolute_import, division, print_function')\n\nexplainer = lime_image.LimeImageExplainer(verbose = 1)\nsegmenter = SegmentationAlgorithm('slic', n_segments=100, compactness=1, sigma=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputIMG = cv2.imread(test_data_directory+\"/\"+sample_type+\"/\"+sample_random_img , 1)\n\n\n # get explanation from LIME\nexplanation = explainer.explain_instance(inputIMG, classifier_fn = NewModel.predict ,  segmentation_fn=segmenter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_regions=[1,3,5]\nprint('Image Classified as:', list_of_classes[explanation.top_labels[0]])\nfor i in num_regions:\n        temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=i, hide_rest=False)\n        plt.figure()\n        plt.imshow(mark_boundaries(temp, mask))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}