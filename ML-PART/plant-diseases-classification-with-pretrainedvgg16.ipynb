{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\n####Import Library\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom keras.preprocessing.image import ImageDataGenerator, load_img\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense,ZeroPadding2D, Activation, BatchNormalization\nfrom keras.callbacks import CSVLogger, ReduceLROnPlateau, EarlyStopping\nimport glob\nimport cv2\nfrom keras import optimizers\nfrom keras.callbacks import ModelCheckpoint\n\n\n\n\n###Define Constants\nFAST_RUN = False\nIMAGE_WIDTH=224\nIMAGE_HEIGHT=224\nIMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\nIMAGE_CHANNELS=3\nbatch_size = 128\nepochs = 8\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pip install split-folders\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nimport split_folders\nsplit_folders.ratio('../input/plantvillage-dataset/color', output=\"output\", seed=1337, ratio=(.7, .15,.15))\n\n\ntrain_data_directory  = \"./output/train\"\nvalidation_data_directory  = \"./output/val\"\ntest_data_directory=\"./output/test\"\nnum_of_classes_on_trainDataset=print(len(glob.glob(train_data_directory +\"/*\")))\nnum_of_classes_on_valDataset=print(len(glob.glob(validation_data_directory+\"/*\")))\nnum_of_classes_on_testDataset=print(len(glob.glob(test_data_directory+\"/*\")))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n##Image Preprocessing\ntrain_datagenerator = ImageDataGenerator(rescale=1./255,\n                                   shear_range=0.2,\n                                   zoom_range=0.2,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   rotation_range=40,\n                                   horizontal_flip=True,\n                                   fill_mode='nearest')\nvalid_datagenerator = ImageDataGenerator(rescale=1./255)\ntraining_set = train_datagenerator.flow_from_directory(train_data_directory ,\n                                                 target_size=IMAGE_SIZE,\n                                                 batch_size=batch_size,\n                                                 class_mode='categorical')\n\nvalid_set = valid_datagenerator.flow_from_directory(validation_data_directory,\n                                            target_size=IMAGE_SIZE,\n                                            batch_size=batch_size,\n                                            class_mode='categorical')\n\ntest_datagenerator = ImageDataGenerator(rescale=1./255)\ntest_set = test_datagenerator.flow_from_directory(\n    test_data_directory, \n    class_mode='categorical',\n    target_size=IMAGE_SIZE,\n    batch_size=batch_size,\n    shuffle=False\n)\n\n\nnumber_of_classes= print(len(glob.glob(train_data_directory +\"/*\")))\nnumber_of_train_images=training_set.samples\nprint(number_of_train_images)\nnumber_of_val_images=valid_set.samples\nprint(number_of_val_images)\nnumber_of_test_images=test_set.samples\nprint(number_of_test_images)\n\n\n\nprint(training_set.class_indices)\n\n\nlist_of_classes = list(training_set.class_indices.keys())\nprint(list_of_classes)\n\n\n\n\n##See Random sample image\nsample_type= random.choice(list_of_classes)\nprint(sample_type)\n\nsample_random_img= random.choice(os.listdir(train_data_directory+\"/\"+sample_type))\nprint(sample_random_img)\n\nimage=load_img(train_data_directory+\"/\"+sample_type+\"/\"+sample_random_img)\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nmodel=tf.keras.applications.VGG16(\n    include_top=False,\n    input_shape=(224, 224, 3),\n    weights=\"imagenet\")\n   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.applications.vgg16 import VGG16\nfrom keras.utils.vis_utils import plot_model\n\nplot_model(model, to_file='vgg.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable = False\n    \nmodel.get_layer('block5_conv1').trainable = True\nmodel.get_layer('block5_conv2').trainable = True\nmodel.get_layer('block5_conv3').trainable = True\nmodel.get_layer('block5_pool').trainable = True\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NewModel=Sequential()\nNewModel.add(model)\n\nNewModel.add(Flatten())\nNewModel.add(Dense(units=4096,activation=\"relu\"))\nNewModel.add(Dropout(0.25))\nNewModel.add(BatchNormalization())\n#L15\nNewModel.add(Dense(units=4096,activation=\"relu\"))\nNewModel.add(Dropout(0.25))\nNewModel.add(BatchNormalization())\n\n\n#L16\nNewModel.add(Dense(units=38, activation=\"softmax\"))\nNewModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nopt = tf.keras.optimizers.Adam(lr = 1e-4, decay = 1e-6)\nNewModel.compile(loss=\"categorical_crossentropy\", optimizer = opt,metrics = [\"accuracy\"])\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau ,ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"VGG_2_Pre.hdf5\",  monitor = 'accuracy', verbose = 1, save_best_only = True, save_weights_only = False, mode = 'auto', period = 1)\nhistory_train= NewModel.fit_generator(training_set,\n                         steps_per_epoch=number_of_train_images//batch_size,\n                         validation_data=valid_set,\n                         epochs=epochs,\n                         validation_steps=number_of_val_images//batch_size,\n                         callbacks=[checkpoint],\n                          verbose=1\n                         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath=\"VGG_2_Pre.h5\"\nNewModel.save(filepath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = NewModel.evaluate_generator(test_set, steps=number_of_test_images, verbose=1,workers=3)\nprint('Testing data   -> loss: %.3f, acc: %.3f' % (loss, acc))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\n\nacc = history_train.history['accuracy']\nval_acc = history_train.history['val_accuracy']\nloss = history_train.history['loss']\nval_loss = history_train.history['val_loss']\n\nepochs = range(len(acc))\n#Accuracy\nxmin = 0.0\nxmax = 8.0\nymin = 0.30\nymax = 1.0\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure()\n#Loss\nxmin = 0.0\nxmax = 8.0\nymin = 0.0\nymax = 1\naxes = plt.gca()\naxes.set_xlim([xmin,xmax])\naxes.set_ylim([ymin,ymax])\n\n\nplt.plot(epochs, loss, 'r', label = 'Training Loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom keras.preprocessing import image\nsample_type= random.choice(list_of_classes)\nprint(\" original filename \" + sample_type)\n\nsample_random_img= random.choice(os.listdir(test_data_directory+\"/\"+sample_type))\n\n\nnew_image=load_img(test_data_directory+\"/\"+sample_type+\"/\"+sample_random_img ,target_size=(227, 227))\n\n\nimg = image.img_to_array(new_image)\nimg = np.expand_dims(img, axis=0)\nimg = img/255\n\nprint(\"Following is our prediction:\")\nprediction = NewModel.predict(img)\nd = prediction.flatten()\nj = d.max()\nfor index,item in enumerate(d):\n    if item == j:\n        class_name = list_of_classes[index]\n    \n\nimg_prob =NewModel.predict_proba(img)\nprint(img_prob.max() )\n\nplt.figure(figsize = (4,4))\nplt.imshow(new_image)\nplt.axis('off')\nplt.title(class_name)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}